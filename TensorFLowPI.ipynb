{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFLowPI.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfBKLgYiz8BiQbPWOmDfUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diego690/AppSchool/blob/main/TensorFLowPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VUcWRq6M8u23"
      },
      "outputs": [],
      "source": [
        "##importamos librerias de tensorflow \n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#descargamos el set de datos que vamos a utilizar como ejemplo que seria perros y gatos\n",
        "#por las fallas que presenta estos meses\n",
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
        "datos, metadatos = tfds.load('cats_vs_dogs', as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "sc3KCB1X_jmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizamos los datos\n",
        "metadatos"
      ],
      "metadata": {
        "id": "0NuHIN6VEo4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#si queremos mostrar 5 ejemplos del set de datos\n",
        "tfds.as_dataframe(datos['train'].take(5),metadatos)"
      ],
      "metadata": {
        "id": "xuDyP0lpFB7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ahora si queremos algo mas \"bonito\"\n",
        "tfds.show_examples(datos['train'].take(5),metadatos)"
      ],
      "metadata": {
        "id": "kiXvEzpLFkQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ahora si queremos un control total de lo que queremos ver tenemos:\n",
        "import matplotlib.pyplot as plt\n",
        "#ahora si queremos que todas las imagenes tenga una sola dimension \n",
        "import cv2\n",
        "#agregamos un iteracion para las imagenes segun queramos visualizarlas\n",
        "\n",
        "#primero si queremos que las imagenes tenga un tama単o general \n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "#tama単no de la imagen que luego se redimensionara\n",
        "TAMANO_IMG = 100\n",
        "\n",
        "#un for para recorrer hasta donde queramos mostrar\n",
        "for i, (imagen, etiqueta) in enumerate(datos['train'].take(2)):\n",
        "  imagen = cv2.resize(imagen.numpy(),(TAMANO_IMG,TAMANO_IMG))#redimensiono las imagenes\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)#cambiamos el color a b/n para mayor rapidez\n",
        "  plt.subplot(5,5, i+1) #tama単o de la matriz si queremos usar mas de 5 imagenes\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(imagen,cmap='gray') #mostramos las imagenes"
      ],
      "metadata": {
        "id": "p5IHeRjcGfV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_entrenamiento = []"
      ],
      "metadata": {
        "id": "DRhD3PuHOq80"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#para todos los datos de entranamiento\n",
        "for i, (imagen,etiqueta) in enumerate(datos['train']):\n",
        "  imagen = cv2.resize(imagen.numpy(),(TAMANO_IMG,TAMANO_IMG))\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)#cambiamos el color a b/n para mayor rapidez\n",
        "  #para las imagenes modificadas junto con el cambio de forma y junto con el solo canal de color \n",
        "  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG,1)#cambiar tama単o 100,100,1\n",
        "  datos_entrenamiento.append([imagen,etiqueta])"
      ],
      "metadata": {
        "id": "jK5g0x9qMTSm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_entrenamiento[0] #primer indice, donde los valores de los pixele mostramos, y el numpy que es 1 para perro y 0 para gato"
      ],
      "metadata": {
        "id": "MHHklYG6QvDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(datos_entrenamiento)#imagenes en el arreglo"
      ],
      "metadata": {
        "id": "9W1tNCqoRBop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ahora preparamos los datos para el entramiento \n",
        "#creo dos variables x, y\n",
        "X = [] #paa las imagens de entrada, es decir, pixeles\n",
        "y = [] #para las etiquetas (perro o gato)\n",
        "\n",
        "for imagen, etiqueta in datos_entrenamiento:\n",
        "  X.append(imagen)\n",
        "  y.append(etiqueta)"
      ],
      "metadata": {
        "id": "upgsL5_3RuZw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "Lm0lskIoTAP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ahora normalizamos los datos\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(X).astype(float)/255"
      ],
      "metadata": {
        "id": "1TIuA6qeTTMr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(y) #etiquetas en un arreglo simple"
      ],
      "metadata": {
        "id": "0odQO446UB00"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "qi-EYKi7UM9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape#info del arreglo"
      ],
      "metadata": {
        "id": "A0odT73EUsq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#probamos modelo denso\n",
        "modeloDenso = tf.keras.models.Sequential([\n",
        "                                          tf.keras.layers.Flatten(input_shape=(100,100,1)),\n",
        "                                          tf.keras.layers.Dense(150,activation='relu'),#con 150 neuronas \n",
        "                                          tf.keras.layers.Dense(150,activation='relu'),\n",
        "                                          tf.keras.layers.Dense(1,activation='sigmoid')#una neurona de salida con activacion para decir si es perrro o gato\n",
        "\n",
        "])\n",
        "#modelo convulocional, con 3 capas convulucionales y agrupacion maxima 32,64,128 filtros\n",
        "modeloCNN = tf.keras.models.Sequential([\n",
        "                                       tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "                                        tf.keras.layers.MaxPool2D(2,2),\n",
        "                                         tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "                                        tf.keras.layers.MaxPool2D(2,2),\n",
        "                                         tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
        "                                        tf.keras.layers.MaxPool2D(2,2),\n",
        "\n",
        "                                        #con una capa densa de 100 neuronas con\n",
        "                                        tf.keras.layers.Flatten(),\n",
        "                                        #con una salida con sigmoid\n",
        "                                        tf.keras.layers.Dense(100,activation='relu'),\n",
        "                                        tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "#modelo cnn2\n",
        "modeloCNN2 = tf.keras.models.Sequential([\n",
        "                                       tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "                                        tf.keras.layers.MaxPool2D(2,2),\n",
        "                                         tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "                                        tf.keras.layers.MaxPool2D(2,2),\n",
        "                                         tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
        "                                        tf.keras.layers.MaxPool2D(2,2),\n",
        "\n",
        "                                        #con un dropout de 1/2 antes de la capa densa de 250 neuronas\n",
        "                                        tf.keras.layers.Dropout(0.5),\n",
        "                                        tf.keras.layers.Flatten(),\n",
        "                                        #con una salida con sigmoid\n",
        "                                        tf.keras.layers.Dense(250,activation='relu'),\n",
        "                                        tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "YP6DGkMXVxjU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#para compilar los modelos se puede utilizar en este caso que solo tenemos 2 objetos, el crossentropy\n",
        "modeloDenso.compile(optimizer = 'adam',\n",
        "                    loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN.compile(optimizer = 'adam',\n",
        "                    loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN2.compile(optimizer = 'adam',\n",
        "                    loss = 'binary_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_0sl7wpAoQQn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utilizamos la siguiente libreria para saber como estan funcionando los modelos \n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "metadata": {
        "id": "4sU8Qxx6taKc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gc import callbacks\n",
        "#creamos una carpeta para cada modelo\n",
        "tensorboardDenso = TensorBoard(log_dir='logs/denso')\n",
        "#con fit le mando la X(imagenes) y las Y(etiquetas) y el lote, dejando un % para pruebas\n",
        "modeloDenso.fit(X,y,batch_size=32,\n",
        "                validation_split = 0.15,\n",
        "                epochs = 100,\n",
        "                callbacks=[tensorboardDenso])# por cada epoca que recorra y al final guarda en un archivo \n",
        "\n"
      ],
      "metadata": {
        "id": "lcUsREKjtu9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creamos una carpeta para cada modelo\n",
        "tensorboardCNN = TensorBoard(log_dir='logs/cnn')\n",
        "#con fit le mando la X(imagenes) y las Y(etiquetas) y el lote, dejando un % para pruebas\n",
        "modeloCNN.fit(X,y,batch_size=32,\n",
        "                validation_split = 0.15,\n",
        "                epochs = 100,\n",
        "                callbacks=[tensorboardCNN])# por cada epoca que recorra y al final guarda en un archivo \n"
      ],
      "metadata": {
        "id": "HKDEgymWzVB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creamos una carpeta para cada modelo\n",
        "tensorboardCNN2 = TensorBoard(log_dir='logs/cnn2')\n",
        "#con fit le mando la X(imagenes) y las Y(etiquetas) y el lote, dejando un % para pruebas\n",
        "modeloCNN2.fit(X,y,batch_size=32,\n",
        "                validation_split = 0.15,\n",
        "                epochs = 100,\n",
        "                callbacks=[tensorboardCNN2])# por cada epoca que recorra y al final guarda en un archivo "
      ],
      "metadata": {
        "id": "O6r2wE-j3ti6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizamos los datos en tensorboard\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNLVJm9nv-gs",
        "outputId": "a78e7cab-1c28-481c-b305-ee0a9d17144a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lanzamos la caperta donde se \n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "oKYcV9BTwLUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 3106"
      ],
      "metadata": {
        "id": "ehu0doo28ckP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "for i in range(10):\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(X[i].reshape(100,100), cmap='gray')"
      ],
      "metadata": {
        "id": "VcjnKa-s83jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aumento de datos en el entrenamiento\n",
        "#Realizar el aumento de datos con varias transformaciones. Al final, graficar 10 como ejemplo\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 30, #rotacion aleatoria de las imagenes\n",
        "    width_shift_range=0.2,#mover de los lados\n",
        "    height_shift_range=0.2,#mover arriba y abajo\n",
        "    shear_range=15,#inclinacion de imagen\n",
        "    zoom_range=[0.7, 1.4], # que tan peque単o el acercamiento de la imagen\n",
        "    horizontal_flip=True,# roataciones \n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X) #para darle el arreglo de imagenes a la funcion fit\n",
        "#esto espara que el generador entienda todo lo referente al tama単o de las imagenes y que pueda ver como hara las transformaciones cuando se lo pida\n",
        "\n",
        "#ahora para las imagenes transformadas hay muchas funciones\n",
        "plt.figure(figsize=(20,8))\n",
        "#con el flow le damos las imagenes, en este caso 10, y q las de en el orden original\n",
        "#y como flow es un iterador lo ponemos en un for\n",
        "\n",
        "for imagen, etiqueta in datagen.flow(X, y, batch_size=10, shuffle=False):\n",
        "  for i in range(10):\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(X[i].reshape(100,100), cmap='gray')\n",
        "  break"
      ],
      "metadata": {
        "id": "cLkWDrk99t0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloDenso_AD = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modeloCNN_AD = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modeloCNN2_AD = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(250, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "pV5Ps25EAt58"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloDenso_AD.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN_AD.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN2_AD.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JMQ-5yFQA2MD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#para el aumento de datos si toca separar datos de entramientos y de pruebas\n",
        "len(X) * .85 #19700\n",
        "len(X) - 19700 #3562\n",
        "\n",
        "#definimos dos variables\n",
        "X_entrenamiento = X[:19700] #desde el inicion hasta el valor 19700 -->85% de entramiento\n",
        "X_validacion = X[19700:] #desde el punto donde se quedo hasta el final del arreglo ---> 15% de pruebas\n",
        "\n",
        "#ahora para las etiquetas el mismo procedimiento que con las X\n",
        "#definimos dos variables\n",
        "y_entrenamiento = y[:19700] #desde el inicion hasta el valor 19700 -->85% de entramiento\n",
        "y_validacion = y[19700:] #desde el punto donde se quedo hasta el final del arreglo ---> 15% de pruebas"
      ],
      "metadata": {
        "id": "L7AJS7ImA-lW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preeparar el generador de datos transformados para el entrenamiendo de datos\n",
        "#Usar la funcion flow del generador para crear un iterador que podamos enviar como entrenamiento a la funcion FIT del modelo\n",
        "data_gen_entrenamiento = datagen.flow(X_entrenamiento, y_entrenamiento, batch_size=32)"
      ],
      "metadata": {
        "id": "A9ngVmmgCKhy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB0O5azAEMGU",
        "outputId": "a7307f2a-619b-4421-a334-49241d3498cb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46068"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboardCNN_AD = TensorBoard(log_dir='logs-new/cnn_AD')\n",
        "\n",
        "modeloCNN_AD.fit(\n",
        "    data_gen_entrenamiento,\n",
        "    epochs=150, batch_size=32,\n",
        "    validation_data=(X_validacion, y_validacion),\n",
        "    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),\n",
        "    validation_steps=int(np.ceil(len(X_validacion) / float(32))),\n",
        "    callbacks=[tensorboardCNN_AD]\n",
        ")"
      ],
      "metadata": {
        "id": "GP0vGFLsDzY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloCNN_AD.save('perros-gatos-cnn-ad.h5')"
      ],
      "metadata": {
        "id": "1iPknzsaJa5w"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "zXSfeC7XJbnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir carpeta_salida"
      ],
      "metadata": {
        "id": "XN0timbqJdqu"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}